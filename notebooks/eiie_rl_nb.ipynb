{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "from datetime import datetime, timedelta\n",
    "from time import time\n",
    "\n",
    "from cryptotrader.exchange_api.poloniex import Poloniex\n",
    "from cryptotrader.envs.trading import BacktestDataFeed, BacktestEnvironment\n",
    "from cryptotrader.envs.utils import make_balance, convert_to\n",
    "from cryptotrader.agents import cn_agents\n",
    "from cryptotrader.utils import array_normalize\n",
    "#from cryptotrader.agents.apriori import TCOTrader\n",
    "\n",
    "import chainer as cn\n",
    "from chainerrl import misc\n",
    "from chainerrl.optimizers.nonbias_weight_decay import NonbiasWeightDecay\n",
    "from chainerrl.optimizers import rmsprop_async\n",
    "from chainerrl import experiments\n",
    "from chainerrl.agents import a3c\n",
    "from chainerrl.experiments.hooks import LinearInterpolationHook\n",
    "\n",
    "from cryptotrader.agents.cn_agents import A3CEIIE, phi, PrintProgress, PortfolioVector, ProcessObs, batch_states, VisionModel, EIIE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from bokeh.io import output_notebook\n",
    "from jupyterthemes import jtplot\n",
    "output_notebook()\n",
    "jtplot.style()\n",
    "%matplotlib inline\n",
    "# %load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation Params\n",
    "test_name = 'EIIE_PTP_agent'\n",
    "obs_steps = 50 # Observation steps, number of candles required by the agent for calculations\n",
    "period = 120 # Observation period in minutes, also trading frequency\n",
    "pairs = [\"USDT_BTC\", \"USDT_ETH\", \"USDT_LTC\", \"USDT_XRP\", \"USDT_XMR\", \"USDT_ETC\", \"USDT_ZEC\", \"USDT_DASH\"] # Universe, some survivor bias here...\n",
    "fiat_symbol = 'USDT' # Quote symbol\n",
    "init_funds = make_balance(crypto=0.0, fiat=100.0, pairs=pairs) # Initial equally distributed portfolio\n",
    "data_dir = './data' # Data directory for offline testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papi = Poloniex()\n",
    "def make_env(process_idx, test):\n",
    "    tapi = BacktestDataFeed(papi, period, pairs=pairs, balance=init_funds, load_dir=data_dir)\n",
    "    tapi.load_data('/train')\n",
    "\n",
    "    # Environment setup\n",
    "    env = BacktestEnvironment(period, obs_steps, tapi, fiat_symbol, test_name)\n",
    "    obs = env.reset();\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Environment setup\n",
    "# Data feed setup\n",
    "papi = Poloniex()\n",
    "tapi = BacktestDataFeed(papi, period, pairs=pairs, balance=init_funds, load_dir=data_dir)\n",
    "\n",
    "# # Download new data from the exchange\n",
    "# tapi.download_data(end=datetime.timestamp(datetime.utcnow() - timedelta(days=100)),\n",
    "#                        start=datetime.timestamp(datetime.utcnow() - timedelta(days=300)))\n",
    "\n",
    "# # And save it to disk, if you want to\n",
    "# tapi.save_data(data_dir + '/train')\n",
    "\n",
    "# Or load data from disk\n",
    "tapi.load_data('/train')\n",
    "\n",
    "# Environment setup\n",
    "env = BacktestEnvironment(period, obs_steps, tapi, fiat_symbol, test_name)\n",
    "#env.add_pairs(pairs)\n",
    "env.fiat = fiat_symbol\n",
    "obs = env.reset();\n",
    "\n",
    "# Setup eval ent\n",
    "# Or load data from disk\n",
    "#tapi = BacktestDataFeed(papi, period, pairs=pairs, balance=init_funds, load_dir=data_dir)\n",
    "#tapi.load_data('/eval')\n",
    "\n",
    "# Environment setup\n",
    "eval_env = BacktestEnvironment(period, obs_steps, tapi, fiat_symbol, test_name)\n",
    "#eval_env.add_pairs(pairs)\n",
    "eval_env.fiat = fiat_symbol\n",
    "eval_env.reset();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN params\n",
    "timesteps = obs.shape[0] - 1\n",
    "n_filters_in = 8\n",
    "n_filters_out = 64\n",
    "\n",
    "processes = 8\n",
    "seed = 42\n",
    "outdir = './save'\n",
    "\n",
    "# Training params\n",
    "t_max = 8 # Timesteps before update main model\n",
    "max_episode_len = 4 # Max timesteps per episode\n",
    "beta = (1e-3, 0.) # entropy regularization weight for policy\n",
    "reward_scale_factor = 1. # reward scale factor\n",
    "gamma = 0.99 # discount factor\n",
    "alpha = 0.99 # Exponential decay rate of the second order moment for rmsprop optimizer\n",
    "rmsprop_epsilon = 1e-7 # fuzz factor, for numerical estability\n",
    "lr = (1e-3, 1e-5) # learning rate\n",
    "weight_decay = 1e-8 # l2 regularization coef\n",
    "grad_noise = 1e-7 # gradient gaussian noise, improve learning in deep neuronetworks\n",
    "clip_grad = 1. # clip gradient norm\n",
    "steps = 3e2 # Training steps\n",
    "eval_interval = None\n",
    "eval_n_runs = None\n",
    "\n",
    "profile = False\n",
    "render = False\n",
    "demo= False\n",
    "load = False\n",
    "# load = outdir + \"/%.1f_finish\" % (steps)\n",
    "# logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cn_agents.A3CEIIE(timesteps, len(env.symbols), n_filters_in, n_filters_out)#.to_gpu(0)\n",
    "\n",
    "opt = rmsprop_async.RMSpropAsync(lr=lr[0], eps=rmsprop_epsilon, alpha=alpha)\n",
    "opt.setup(model)\n",
    "opt.add_hook(cn.optimizer.GradientClipping(clip_grad))\n",
    "# opt.add_hook(optimizer.GradientNoise(grad_noise))\n",
    "opt.add_hook(cn.optimizer.WeightDecay(weight_decay))\n",
    "\n",
    "agent = a3c.A3C(model,\n",
    "                opt,\n",
    "                t_max=t_max,\n",
    "                gamma=gamma,\n",
    "                beta=beta[0],\n",
    "                phi=phi,\n",
    "                normalize_grad_by_t_max=True,\n",
    "                act_deterministically=False,\n",
    "                v_loss_coef=1.0\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "load = False\n",
    "# load = outdir + \"/%.1f_finish\" % (steps)\n",
    "if load:\n",
    "    agent.load(load)\n",
    "    print(\"Model loaded from %s\" % (load))\n",
    "\n",
    "# else:\n",
    "pp = PrintProgress(time())\n",
    "\n",
    "def lr_setter(env, agent, value):\n",
    "    agent.optimizer.lr = value\n",
    "    \n",
    "def beta_setter(env, agent, value):\n",
    "    agent.beta = value\n",
    "\n",
    "lr_decay = LinearInterpolationHook(steps, lr[0], lr[1], lr_setter)\n",
    "beta_decay = LinearInterpolationHook(steps / 3, beta[0], beta[1], beta_setter)\n",
    "    \n",
    "try:\n",
    "    with np.errstate(divide='ignore'):\n",
    "        agent = experiments.train_agent_async(\n",
    "            agent=agent,\n",
    "            outdir=outdir,\n",
    "            processes=processes,\n",
    "            make_env=make_env,\n",
    "            profile=profile,\n",
    "            steps=steps,\n",
    "            eval_n_runs=eval_n_runs,\n",
    "            eval_interval=eval_interval,\n",
    "            max_episode_len=max_episode_len,\n",
    "            global_step_hooks=[pp, lr_decay, beta_decay]\n",
    "            )\n",
    "except KeyboardInterrupt:\n",
    "    #load = outdir + 0/\"%.1f_finish\" % (agent.t)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "load = outdir + \"/%.1f_finish\" % (steps)\n",
    "if load:\n",
    "    agent.load(load)\n",
    "    print(\"Model loaded from %s\" % (load))\n",
    "\n",
    "agent.act_deterministically = False\n",
    "eval_stats = experiments.eval_performance(\n",
    "    env=eval_env,\n",
    "    agent=agent,\n",
    "    n_runs=1,\n",
    "    max_episode_len=eval_env.data_length)\n",
    "\n",
    "print('mean: {} median: {} stdev {}'.format(eval_stats['mean'], eval_stats['median'], eval_stats['stdev']))\n",
    "eval_env.plot_results();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
